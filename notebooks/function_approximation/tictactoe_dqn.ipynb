{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Setup Environment\n",
        "import sys\n",
        "import os\n",
        "ROOT = '../../'\n",
        "sys.path.append(ROOT)\n",
        "\n",
        "from pettingzoo.classic import tictactoe_v3\n",
        "import numpy as np\n",
        "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
        "from IPython.display import HTML\n",
        "from source.agents.dqn_agent import DQNAgent\n",
        "from source.agents.random_agent import RandomAgent\n",
        "from source.utils import utils\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import random\n",
        "from typing import Dict, Optional, Tuple\n",
        "from collections import defaultdict\n",
        "from source.agents.agent import Agent\n",
        "from pettingzoo.utils.env import AECEnv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:05<00:00, 181.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step: 0, epsilon: 0.270133977467853, average_return: 0.447, success rate: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:05<00:00, 179.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step: 1, epsilon: 0.10833698886122343, average_return: 0.603, success rate: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 576/1000 [00:03<00:02, 189.68it/s]"
          ]
        }
      ],
      "source": [
        "# Policy Eval\n",
        "# Params\n",
        "num_epoch = 5\n",
        "num_episode = 1000\n",
        "video_path = os.path.join(ROOT, \"video/dqn_tictactoe.mp4\")\n",
        "random_seed = 101\n",
        "\n",
        "# Initialize\n",
        "history = []\n",
        "total_reward = 0\n",
        "# set random seeds\n",
        "rng = np.random.default_rng(random_seed)\n",
        "#random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "#torch.manual_seed(random_seed)\n",
        "# epsilon decay\n",
        "epsilon_schedule = utils.create_decay_schedule(num_epoch)\n",
        "lr_schedule = utils.create_decay_schedule(num_epoch)\n",
        "\n",
        "# Create Environment.\n",
        "#env = gym.make('Taxi-v3')\n",
        "# using render_mode=rgb_array so that video recording works\n",
        "#env = gym.make(\n",
        "#    \"LunarLander-v2\",\n",
        "#    render_mode='rgb_array'\n",
        "#)\n",
        "#env = gym.make(\"CarRacing-v2\", render_mode='rgb_array', continuous=False)\n",
        "#env = gym.make(\"CartPole-v1\", render_mode='rgb_array')\n",
        "\n",
        "env = tictactoe_v3.env()\n",
        "env.np_random = rng\n",
        "\n",
        "# Create Agent\n",
        "dqn_agent = DQNAgent(\n",
        "    state_space=env.observation_space('player_1')['observation'],\n",
        "    action_space=env.action_space('player_1'),\n",
        "    discount_rate=0.99,\n",
        "    epsilon=None, # use epsilon_schedule\n",
        "    learning_rate=1e-4,\n",
        "    learning=True,\n",
        "    batch_size = 8,\n",
        "    tau = 0.005,\n",
        "    eps_decay=3000\n",
        ")\n",
        "random_agent = RandomAgent(    \n",
        "    state_space=env.observation_space('player_2')['observation'],\n",
        "    action_space=env.action_space('player_2'),\n",
        "    discount_rate=None,\n",
        "    epsilon=None, # use epsilon_schedule\n",
        "    learning_rate=None,\n",
        "    learning=False\n",
        ")\n",
        "agent_dict = {'player_1': dqn_agent, 'player_2':random_agent}\n",
        "eps_history = []\n",
        "hisotry = []\n",
        "# Start Learning\n",
        "for i in range(num_epoch):\n",
        "    success = 0\n",
        "    for _ in tqdm(range(num_episode)):\n",
        "        reward, steps = utils.play_multiagent_episode(agent_dict, env)#,epsilon=epsilon_schedule[i])\n",
        "        history.append(reward['player_1'])\n",
        "        eps_history.append(agent_dict['player_1']._epsilon)\n",
        "        total_reward += reward['player_1']\n",
        "    #score = agent.update()\n",
        "    print(\n",
        "        f\"step: {i}, epsilon: {dqn_agent._epsilon}, average_return: {np.mean(history)}, success rate: {success / num_episode}\")\n",
        "print(f\"\\nrewarding episodes: {total_reward}\")\n",
        "\n",
        "# For off policy learning only: get greedy policy (no exploration)\n",
        "#agent._policy = get_epsilon_greedy_policy_from_action_values(agent._Q.weight)\n",
        "# Run Eval\n",
        "avarge_return, num_episode = utils.evaluate_multiagent(agent_dict, env, 5000)\n",
        "for ag_id, value in avarge_return.items():\n",
        "    print(f\"{ag_id}: Average return = {value / num_episode}\")\n",
        "\n",
        "utils.plot_history(history)\n",
        "utils.plot_history(eps_history, smoothing=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'source.utils.utils' has no attribute 'play_episode'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m env \u001b[39m=\u001b[39m tictactoe_v3\u001b[39m.\u001b[39menv(render_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m reward, _ \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mplay_episode(agent_dict, env)\n\u001b[1;32m      3\u001b[0m \u001b[39m#html=utils.render_mp4(video_path)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m#HTML(html)\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'source.utils.utils' has no attribute 'play_episode'"
          ]
        }
      ],
      "source": [
        "env = tictactoe_v3.env(render_mode='human')\n",
        "reward, _ = utils.play_multiagent_episode(agent_dict, env)\n",
        "#html=utils.render_mp4(video_path)\n",
        "#HTML(html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b007964239c9846de49217bea874a76b6e18c6041f326c6a02623c321aae0990"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
